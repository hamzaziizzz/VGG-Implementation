{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81a60b5d",
   "metadata": {
    "id": "81a60b5d"
   },
   "source": [
    "### Downloading Zipped Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfbd2a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2cfbd2a1",
    "outputId": "1511fe75-a9ac-4df2-bfbd-50b2bd59b7d8"
   },
   "outputs": [],
   "source": [
    "!wget -O Indian-Bird-Species.zip \"https://www.dropbox.com/scl/fi/2054v5dycvdjy37gmt9ex/Indian-Bird-Species.zip?rlkey=q1siybqz3tzp4xtvyj35vkum4&dl=0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aede27",
   "metadata": {
    "id": "67aede27"
   },
   "source": [
    "### Creating Directory to Move Unzipped Data to this Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbbc134",
   "metadata": {
    "id": "2dbbc134"
   },
   "outputs": [],
   "source": [
    "!mkdir Indian-Bird-Species"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Unzipping Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fa580b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9fa580b",
    "outputId": "04b6c9b7-b53b-4446-9367-b0e31c717e53"
   },
   "outputs": [],
   "source": [
    "!unzip Indian-Bird-Species.zip -d Indian-Bird-Species/"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# VGG-19 Implementation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importing Dependencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bba892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OS to interact with the operating system\n",
    "import os\n",
    "\n",
    "# Import OpenCV, which is a Computer Vision library, and here we use it to deal with our image dataset\n",
    "import cv2\n",
    "\n",
    "# Import NumPy as our model trains on arrays which will be handled by NumPy\n",
    "import numpy as np\n",
    "\n",
    "# Import mayplotlib and seaborn to visualize the metrics of our model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import Shutil to move, copy and delete directories and subdirectories\n",
    "import shutil\n",
    "\n",
    "# Import Math to use some mathematical computations\n",
    "import math\n",
    "\n",
    "# Import Keras ImageDataGenerator which is used for getting the input of the original data and further, it makes the transformation of this data on a random basis and gives the output resultant containing only the data that is newly transformed.\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "# Import EarlyStopping and ModelCheckpoint\n",
    "# EarlyStopping is used to halt the learning of the used when the model's accuracy does not improve by any significant amount\n",
    "# ModelCheckpoint is used to save the model or weights in a checkpoint file at some time interval\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Import categorical_crossentropy\n",
    "# categorical cross entropy compares each of the predicted probabilities to actual class output. It then calculates the score that penalizes the probabilities based on the distance from the expected value. That means how close or far from the actual value.\n",
    "from keras.losses import categorical_crossentropy\n",
    "\n",
    "# Import scikit-learn metrics which will be used to display the metrics of the model\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, precision_recall_curve, average_precision_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splitting Dataset into Training, Validation and Testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e196a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"Indian-Bird-Species\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca589d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files_in_each_directory(directory_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    This function counts the number of images or files in each of the directories or classes of the dataset folder\n",
    "\n",
    "    Arguments:\n",
    "        directory_path: The path of the folder or directory that contains the required classes\n",
    "\n",
    "    Returns:\n",
    "        number_of_images: Number of images or files present in each class\n",
    "    \"\"\"\n",
    "    number_of_images = {}\n",
    "    \n",
    "    # label the number of images in each class of our dataset\n",
    "    for sub_directory in os.listdir(directory_path):\n",
    "        # os.listdir() is used to list or count the number of images in each directory of dataset\n",
    "        # os.path.join() is used to join the parent directory, any subdirectory and the contents of the directory\n",
    "        number_of_images[sub_directory] = len(os.listdir(os.path.join(directory_path, sub_directory)))\n",
    "    \n",
    "    return number_of_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab305a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_images = count_files_in_each_directory(DATASET_PATH)\n",
    "print(dataset_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Randomly display any image from each class of the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa58222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing all the subdirectories in our main dataset directory\n",
    "for bird_directory in os.listdir(DATASET_PATH):\n",
    "    # picking a random image from each class of the dataset\n",
    "    for img in np.random.choice(os.listdir(os.path.join(DATASET_PATH, bird_directory)), size = 2):\n",
    "        # read each image with the help of OpenCV\n",
    "        image = cv2.imread(os.path.join(DATASET_PATH, bird_directory, img))\n",
    "        # plot the image using matplotlib\n",
    "        plt.imshow(image); plt.axis(\"off\")\n",
    "        # give image a title using matplotlib\n",
    "        plt.title(bird_directory)\n",
    "        # show or display the image using matplotlib\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Listing the number of images in each class of our dataset***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3643dd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_images_in_each_directory(number_of_images: dict, folder_name: str) -> None:\n",
    "    \"\"\"\n",
    "    This function prints a list of the total images present in each class.\n",
    "\n",
    "    Arguments:\n",
    "        number_of_images: A dictionary containing the counts of the images present in each directory.\n",
    "        folder_name: The folder name in which the classes are present\n",
    "    \"\"\"\n",
    "    print(f\"The {folder_name} folder contains the following:\")\n",
    "\n",
    "    for i, each_class in enumerate(number_of_images):\n",
    "        listing = f\"{i + 1})\"\n",
    "        print(f\"{listing:<2} {number_of_images[each_class]} images of {each_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_images_in_each_directory(dataset_images, DATASET_PATH)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Declaring and Defining our Custom Function for Splitting the Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def data_folder(folder_name: str, split_ratio: float) -> None:\n",
    "    \"\"\"\n",
    "    This function will split the dataset in a given number of new folders, namely, Training, Testing and Validation in a given ratio.\n",
    "    Such that Training:Testing:Validation = x:y:z\n",
    "    Where,\n",
    "        x is the number of images in Training Folder\n",
    "        y is the number of images in Testing Folder\n",
    "        z is the number of images in Validation Folder\n",
    "\n",
    "    Arguments:\n",
    "        folder_name: Name of the folder created for splitting the dataset\n",
    "        split_ratio: Percentage of images of the original dataset for every split folder_name\n",
    "    \"\"\"\n",
    "\n",
    "    # checking if the folder does not already exist\n",
    "    if not os.path.exists(\"./\" + folder_name):\n",
    "        # if the folder doesn't already exist, then create that folder\n",
    "        print(f\"Creating {folder_name} folder...\")\n",
    "        os.mkdir(\"./\" + folder_name)\n",
    "\n",
    "        # listing all the subdirectories in our main dataset directory\n",
    "        for sub_directory in os.listdir(DATASET_PATH):\n",
    "            # checking if that subdirectory for this folder does not already exist\n",
    "            if not os.path.exists(\"./\" + folder_name + \"/\" + sub_directory):\n",
    "                # if it does not already exist, then create that subdirectory for this folder\n",
    "                print(f\"Creating {sub_directory} directory for {folder_name} folder...\")\n",
    "                os.makedirs(\"./\" + folder_name + \"/\" + sub_directory)\n",
    "    \n",
    "                # picking random images from each class of the dataset and copying it to the Training, Testing or Validation folder\n",
    "                # size for each directory is the product of number of images in each class and the ratio of train, test, validate folders\n",
    "                # For example: if Buffalo contains 1000 images and ratio train:test:validate = 70:15:15, then Testing folder will contain 700 images, Testing folder 150 images and Validation Folder 150 images\n",
    "                for file in np.random.choice(a = os.listdir(os.path.join(DATASET_PATH, sub_directory)), size = (math.floor(split_ratio * dataset_images[sub_directory])), replace = False):\n",
    "\n",
    "                    # pathname of original dataset\n",
    "                    O = os.path.join(DATASET_PATH, sub_directory, file)\n",
    "\n",
    "                    # pathname of split dataset\n",
    "                    D = os.path.join(\"./\" + folder_name, sub_directory)\n",
    "\n",
    "                    # copy each image from the original dataset path to a split dataset path\n",
    "                    shutil.copy(O, D)\n",
    "            else:\n",
    "                print(f\"Can't create {sub_directory} as it already exists in the {folder_name} folder.\")\n",
    "    else:\n",
    "        print(f\"Can't create {folder_name} folder as it already exists.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Creating Training Folder***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_folder(\"Training\", 0.7)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Creating Validation Folder***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_folder(\"Validation\", 0.15)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Creating Testing Folder***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_folder(\"Testing\", 0.15)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"Training\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TEST_PATH = \"Testing\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "VALIDATE_PATH = \"Validation\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Listing the number of images in each class of our Training Folder***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_images = count_files_in_each_directory(TRAIN_PATH)\n",
    "list_images_in_each_directory(train_images, TRAIN_PATH)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Listing the number of images in each class of our Validation Folder***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_images = count_files_in_each_directory(TEST_PATH)\n",
    "list_images_in_each_directory(test_images, TEST_PATH)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Listing the number of images in each class of our Testing Folder***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "validate_images = count_files_in_each_directory(VALIDATE_PATH)\n",
    "list_images_in_each_directory(validate_images, VALIDATE_PATH)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing Images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**ImageDataGenerator()** is used to perform augmentation on a given image. Augmentation means that the images are duplicated with some kind of variations that increase the size of the training set without acquiring new images.\n",
    "Augmentation (or variations) that we performed here are the following:\n",
    "- *zoom_range:* zoom in or zoom out images in a given range\n",
    "- *width_shift_range:* shift the images horizontally in a given range\n",
    "- *height_shift_range:* shift the images vertically in a given range\n",
    "- *shear_range:* compress vertically or horizontally in a given range, the original image is somewhat distorted."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data_generator = ImageDataGenerator(\n",
    "    zoom_range = 0.15,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.15\n",
    ")\n",
    "\n",
    "validate_data_generator = ImageDataGenerator()\n",
    "\n",
    "test_data_generator = ImageDataGenerator()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***flow_from_directory()*** takes the path to a directory & generates batches of augmented data. <br>\n",
    "**Arguments:**\n",
    "- *directory:* string, or path to the directory.\n",
    "- *target_size:* Tuple of integers (height, width), defaults to (256,256). The dimensions to which all images found will be resized.\n",
    "- *batch_size:* Size of the batches of data (default: 32).\n",
    "- *shuffle:* Whether to shuffle the data (default: True) If set to False, sorts the data in alphanumeric order.\n",
    "- *class_mode:* One of \"categorical\", \"binary\", \"sparse\", \"input\", or None. Default: \"categorical\". Determines the type of label arrays that are returned:\n",
    "    - \"categorical\" will be 2D one-hot encoded labels,\n",
    "    - \"binary\" will be 1D binary labels, \"sparse\" will be 1D integer labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: play around with 'batch_size': try with different batch sizes of 16, 64, etc.\n",
    "\n",
    "train_generator = train_data_generator.flow_from_directory(\n",
    "    directory = TRAIN_PATH,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 32,\n",
    "    shuffle = True,\n",
    "    class_mode = 'categorical'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "validate_generator = validate_data_generator.flow_from_directory(\n",
    "    directory = VALIDATE_PATH,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 32,\n",
    "    shuffle = False,\n",
    "    class_mode='categorical'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_generator = test_data_generator.flow_from_directory(\n",
    "    directory = TEST_PATH,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 32,\n",
    "    shuffle = False,\n",
    "    class_mode='categorical'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = list(train_generator.class_indices.keys())\n",
    "NUMBER_OF_CLASSES = len(labels)\n",
    "\n",
    "print(f\"The dataset contains {NUMBER_OF_CLASSES} labels and these are:\")\n",
    "print(labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building VGG Model (19 Layers)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def VGG19(input_shape=(224, 224, 3) | tuple):\n",
    "    \"\"\"\n",
    "    Implementation of the popular VGG-19 with the following architecture:\n",
    "        CONV2D * 2 -> MAX-POOL -> CONV2D * 2 -> MAX-POOL -> CONV2D * 4 -> MAX-POOL -> CONV2D * 4 -> MAX-POOL -> CONV2D * 4 -> MAX-POOL\n",
    "\n",
    "    Arguments:\n",
    "        input_shape: shape of the dataset images\n",
    "\n",
    "    Returns:\n",
    "        model: a Model() instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # BLOCK 1\n",
    "    X = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(X_input)     # layer 1\n",
    "    X = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(X)           # layer 2\n",
    "    X = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(X)\n",
    "\n",
    "    # BLOCK 2\n",
    "    X = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(X)          # layer 3\n",
    "    X = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(X)          # layer 4\n",
    "    X = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(X)\n",
    "\n",
    "    # BLOCK 3\n",
    "    X = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(X)          # layer 5\n",
    "    X = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(X)          # layer 6\n",
    "    X = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(X)          # layer 7\n",
    "    X = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv4')(X)          # layer 8\n",
    "    X = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(X)\n",
    "\n",
    "    # BLOCK 4\n",
    "    X = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(X)          # layer 9\n",
    "    X = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(X)          # layer 10\n",
    "    X = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(X)          # layer 11\n",
    "    X = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv4')(X)          # layer 12\n",
    "    X = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(X)\n",
    "\n",
    "    # BLOCK 5\n",
    "    X = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(X)          # layer 13\n",
    "    X = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(X)          # layer 14\n",
    "    X = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(X)          # layer 15\n",
    "    X = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv4')(X)          # layer 16\n",
    "    X = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(X)\n",
    "\n",
    "    # Create Model\n",
    "    vgg_model = Model(inputs=X_input, outputs=X, name=\"VGG-19\")\n",
    "\n",
    "    # return VGG-19 as a model\n",
    "    return vgg_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "base_model = VGG19(input_shape=(224, 224, 3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "head_model = base_model.output\n",
    "\n",
    "# Flatten the output of our model\n",
    "head_model = Flatten()(head_model)\n",
    "\n",
    "# Constructing fully connected layer\n",
    "head_model = Dense(4096, activation=\"relu\", name=\"fc1\")(head_model)                         # layer 17\n",
    "head_model = Dense(4096, activation=\"relu\", name=\"fc2\")(head_model)                         # layer 18\n",
    "head_model = Dense(NUMBER_OF_CLASSES, activation=\"softmax\", name=\"fc3\")(head_model)         # layer 19"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    inputs = base_model.input,\n",
    "    outputs = head_model\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### `compile` method\n",
    "Configure the model for training.\n",
    "#### *Arguments*\n",
    "- **optimizer:** String (name of optimizer) or optimizer instance.\n",
    "- **loss:** Loss function. Maybe a string (name of loss function), or a `keras.losses` instance.\n",
    "- **metrics:** List of metrics to be evaluated by the model during training and testing. Each of this can be a string (name of a built-in function), function or a keras.metrics instance."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = categorical_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Saving our Model as a JSON File"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Creating a directory to save our models\n",
    "!mkdir model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Saving our model as json file\n",
    "model_json = model.to_json()\n",
    "with open(\"./model/VGG-19.json\", 'w') as json_file:\n",
    "    json_file.write(model_json)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining and Initializing Callbacks for our Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Early Stopping\n",
    "Stop training when a monitored metric has stopped improving.\n",
    "\n",
    "Assuming the goal of training is to maximize the validation accuracy. With this, the metric to be monitored would be 'val_accuracy', and the mode would be 'max'.\n",
    "\n",
    "#### *Arguments*\n",
    "- **monitor:** Quantity to be monitored.\n",
    "- **min_delta:** Minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement.\n",
    "- **mode:** One of {\"auto\", \"min\", \"max\"}. In min mode, training will stop when the quantity monitored has stopped decreasing; in \"max\" mode it will stop when the quantity monitored has stopped increasing; in \"auto\" mode, the direction is automatically inferred from the name of the monitored quantity.\n",
    "- **verbose:** Verbosity mode, 0 or 1. Mode 0 is silent, and mode 1 displays messages when the callback takes an action.\n",
    "- **patience:** Number of epochs with no improvement after which training will be stopped."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor = 'val_accuracy',\n",
    "    min_delta = 0.01,\n",
    "    mode = 'max',\n",
    "    verbose = 1,\n",
    "    patience = 20\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Checkpoint\n",
    "ModelCheckpoint() callback is used in conjunction with training using model.fit() or model.fit_generator to save a model or weights (in a checkpoint file) at some interval, so the model or weights can be loaded later to continue the training from the state saved.\n",
    "\n",
    "A few options this callback provides include:\n",
    "- Whether to only keep the model that has achieved the \"best performance\" so far, or whether to save the model at the end of every epoch regardless of performance.\n",
    "- Definition of 'best'; which quantity to monitor and whether it should be maximized or minimized.\n",
    "- The frequency it should save at. Currently, the callback supports saving at the end of every epoch, or after a fixed number of training batches.\n",
    "- Whether only weights are saved, or the whole model is saved.\n",
    "\n",
    "#### *Arguments*\n",
    "- **filepath:** string or path to save the model file.\n",
    "- **monitor:** The metric name to monitor.\n",
    "    - Prefix the name with \"val_\" to monitor validation metrics.\n",
    "    - Use \"loss\" or \"val_loss\" to monitor the model's total loss.\n",
    "    - If you specify metrics as strings, like \"accuracy\", pass the same string (with or without the \"val_\" prefix).\n",
    "- **save_best_only:** if save_best_only=True, it only saves when the model is considered the \"best\" and the latest best model according to the quantity monitored will not be overwritten.\n",
    "- **mode:** one of {'auto', 'min', 'max'}. If save_best_only=True, the decision to overwrite the current save file is made based on either the maximization or the minimization of the monitored quantity. For val_accuracy, this should be max, for val_loss this should be min, etc. In auto mode, the mode is set to max if the quantities monitored are 'accuracy' and are set to min for the rest of the quantities."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath = './model/best_model.h5',\n",
    "    monitor = 'val_accuracy',\n",
    "    mode = 'max',\n",
    "    save_best_only = True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### model.fit()\n",
    "*Trains the model for a fixed number of epochs (dataset iterations).*\n",
    "\n",
    "#### *Arguments*\n",
    "- **x:** Input data. It could be:\n",
    "    - A Numpy array (or array-like), or a list of arrays (in case, the model has multiple inputs).\n",
    "    - A TensorFlow tensor, or a list of tensors (in case, the model has multiple inputs).\n",
    "    - A dict mapping input names to the corresponding array/tensors, if the model has named inputs.\n",
    "    - A `tf.data` dataset. Should return a tuple of either `(inputs, targets)` or `(inputs, targets, sample_weights)`.\n",
    "    - A generator or keras.utils.Sequence returning `(inputs, targets)` or `(inputs, targets, sample_weights)`.\n",
    "- **validation_data:** this can be either:\n",
    "    - a generator for the validation data\n",
    "    - a list (inputs, targets)\n",
    "    - a list (inputs, targets, sample_weights). on which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data.\n",
    "- **steps_per_epoch:** Total number of steps (batches of samples) to yield from `generator` before declaring one epoch finished and starting the next epoch. It should typically be equal to the number of samples if your dataset divided by the batch size.\n",
    "- **epochs:** Integer. Number of epochs to train the model. An epoch is an iteration over the entire data provided, as defined by `steps_per_epoch`.\n",
    "- **verbose:** Verbosity mode (0 = silent, 1 = progress bar, 2 = one line per epoch).\n",
    "- **callbacks:** List of callbacks to apply during training."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: Play around with 'epochs'. Change the number epochs and note the matrices of the model to see how number of epochs can affect the model accuracy.\n",
    "\n",
    "model_history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data = validate_generator,\n",
    "    epochs = 100,\n",
    "    verbose = 1,\n",
    "    callbacks = [early_stopping, model_checkpoint]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plotting Accuracy vs Validation Accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set()\n",
    "\n",
    "plt.plot(model_history.history['accuracy'], label=\"Accuracy\")\n",
    "plt.plot(model_history.history['val_accuracy'], c='red', label=\"Validation Accuracy\")\n",
    "\n",
    "plt.title(\"Accuracy vs Validation Accuracy\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plotting Loss vs Validation Loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set()\n",
    "\n",
    "plt.plot(model_history.history['loss'], label=\"Loss\")\n",
    "plt.plot(model_history.history['val_loss'], c='red', label=\"Validation Loss\")\n",
    "\n",
    "plt.title(\"Loss vs Validation Loss\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "# Set the y-axis range to [0, 20]\n",
    "plt.ylim(0, 10)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### model.load_weights()\n",
    "Loads all layer weights from a saved files.\n",
    "#### *Arguments*\n",
    "- **filepath:** String, path to the weight file to load."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.load_weights(\"./model/best_model.h5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### model.evaluate()\n",
    "Evaluates the model on a data generator."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(test_generator)\n",
    "\n",
    "print(f\"The accuracy of our model on Testing Data is {(evaluation[1] * 100):.3f}%\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### model.predict()\n",
    "Generates output predictions for the input samples from a data generator.\n",
    "#### *Arguments*\n",
    "- **x:** Input samples (here, generator yielding batches of input samples).\n",
    "- **steps:** Total number of steps (batches of samples) to yield from `generator` before stopping.\n",
    "- **verbose:** verbosity mode, 0 or 1.\n",
    "- **workers:** Maximum number of threads to use for parallel processing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = model.predict(\n",
    "    test_generator,\n",
    "    steps = np.ceil(test_generator.samples / test_generator.batch_size),\n",
    "    verbose = 0,\n",
    "    workers = 0\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(predictions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# number of images in our testing dataset\n",
    "test_generator.samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# batch size for testing data generator\n",
    "test_generator.batch_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Store the predicted outcomes of our model\n",
    "# Get the class with the highest probability for each sample\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(predicted_classes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# classes found in our testing data generator\n",
    "print(test_generator.classes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Metrics for our ResNet-50 Convolutional Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Confusion Matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "c_m = confusion_matrix(test_generator.classes, predicted_classes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set_style(\"ticks\")\n",
    "\n",
    "# Setting default size of the plot\n",
    "# Setting default fontsize used in the plot\n",
    "plt.rcParams['figure.figsize'] = (10.0, 9.0)\n",
    "plt.rcParams['font.size'] = 15\n",
    "\n",
    "\n",
    "# Implementing visualization of Confusion Matrix\n",
    "display_c_m = ConfusionMatrixDisplay(c_m, display_labels=labels)\n",
    "\n",
    "\n",
    "# Plotting Confusion Matrix\n",
    "# Setting a color map to be used\n",
    "display_c_m.plot(cmap='OrRd', xticks_rotation=25)\n",
    "# Other possible options for a color map are:\n",
    "# \"autumn_r\", \"Blues\", \"cool\", \"Greens\", \"Greys\", \"PuRd\", \"copper_r\"\n",
    "\n",
    "\n",
    "# Setting fontsize for xticks and yticks\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "\n",
    "# Giving name to the plot\n",
    "plt.title('Confusion Matrix', fontsize=24)\n",
    "\n",
    "\n",
    "# Saving plot\n",
    "plt.savefig('confusion_matrix.png', transparent=True, dpi=500)\n",
    "\n",
    "# Showing the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Classification Report"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Classification Report contains the following metrics:\\n\")\n",
    "print(classification_report(test_generator.classes, predicted_classes, target_names = labels))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_true_labels = test_generator.classes\n",
    "predictions_matrix = predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Precision-Recall Curve"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set()\n",
    "\n",
    "# Initialize empty lists to store precision, recall, and average precision for each class\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "average_precision_list = []\n",
    "\n",
    "# Iterate over each class\n",
    "for class_idx in range(predictions_matrix.shape[1]):\n",
    "    # Get the predicted probabilities for the current class\n",
    "    predictions_class = predictions_matrix[:, class_idx]\n",
    "\n",
    "    # Convert the one-vs-all labels for the current class\n",
    "    class_labels = (test_true_labels == class_idx).astype(int)\n",
    "\n",
    "    # Calculate precision, recall, and average precision for the current class\n",
    "    precision, recall, threshold = precision_recall_curve(class_labels, predictions_class)\n",
    "    avg_precision = average_precision_score(class_labels, predictions_class)\n",
    "\n",
    "    # Append the results to the respective lists\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    average_precision_list.append(avg_precision)\n",
    "\n",
    "    # Plot the precision-recall curve for the current class\n",
    "    plt.plot(recall, precision, marker='.')\n",
    "\n",
    "# Set the plot labels and title\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "\n",
    "# Show the legend with class names or indices\n",
    "plt.legend(labels)\n",
    "\n",
    "# Calculate the mean Precision-Recall score for multi-class classification\n",
    "mean_average_precision = np.mean(average_precision_list)\n",
    "\n",
    "# Add mean ROC-AUC score as a text annotation on the plot\n",
    "plt.annotate(f\"Mean Average Precision: {mean_average_precision:.4f}\", xy=(0.5, 0.1), xycoords='axes fraction', fontsize=12, color='black')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ROC-AUC Curve"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set()\n",
    "\n",
    "# Initialize empty lists to store false positive rate, true positive rate, and AUC for each class\n",
    "fpr_list = []\n",
    "tpr_list = []\n",
    "auc_list = []\n",
    "\n",
    "# Iterate over each class\n",
    "for class_idx in range(predictions_matrix.shape[1]):\n",
    "    # Get the predicted probabilities for the current class\n",
    "    predictions_class = predictions_matrix[:, class_idx]\n",
    "\n",
    "    # Convert the one-vs-all labels for the current class\n",
    "    class_labels = (test_true_labels == class_idx).astype(int)\n",
    "\n",
    "    # Calculate false positive rate, true positive rate, and AUC for the current class\n",
    "    fpr, tpr, _ = roc_curve(class_labels, predictions_class)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Append the results to the respective lists\n",
    "    fpr_list.append(fpr)\n",
    "    tpr_list.append(tpr)\n",
    "    auc_list.append(roc_auc)\n",
    "\n",
    "    # Plot the ROC curve for the current class\n",
    "    plt.plot(fpr, tpr, marker='.')\n",
    "\n",
    "# Set the plot labels and title\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "\n",
    "# Show the legend with class names or indices\n",
    "plt.legend(labels)\n",
    "\n",
    "# Calculate the mean ROC-AUC score for multi-class classification\n",
    "mean_roc_auc_score = np.mean(auc_list)\n",
    "\n",
    "# Add mean ROC-AUC score as a text annotation on the plot\n",
    "plt.annotate(f\"Mean ROC-AUC: {mean_roc_auc_score:.4f}\", xy=(0.7, 0.2), xycoords='axes fraction', fontsize=12, color='black')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Perform Prediction on Some Random Images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### model.predict()\n",
    "Generates output predictions for the input samples.\n",
    "#### *Arguments*\n",
    "- **x:** Input samples. It could be:\n",
    "    - A Numpy array (or array-like), or a list of arrays (in case, the model has multiple inputs).\n",
    "    - A TensorFlow tensor, or a list of tensors (in case, the model has multiple inputs).\n",
    "    - A generator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### numpy.argmax()\n",
    "Returns the indices of the maximum values along an axis.\n",
    "#### *Arguments*\n",
    "- **a:** *array_like* <br> Input array.\n",
    "- **axis:** *int, optional* <br> By default, the index is into the flattened array, otherwise along the specified axis.\n",
    "- **out:** *array, optional* <br> If provided, the result will be inserted into this array. It should be of the appropriate shape and dtype.\n",
    "- **keepdims:** *bool, optional* <br> If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.\n",
    "#### *Returns*\n",
    "- **index_array:** *ndarray of ints* <br> Array of indices into the array. It has the same shape as a.shape with the dimension along axis removed. If keepdims is set to True, then the size of axis will be 1 with the resulting array having same shape as a.shape."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def predict_image(image_path, nn_model, classes):\n",
    "    \"\"\"\n",
    "    This function takes an image path as an argument and predicts its class using the provided model.\n",
    "\n",
    "    Arguments:\n",
    "        image_path: string, the path of the image.\n",
    "        nn_model: the pre-trained model used for prediction.\n",
    "        classes: list of strings, containing the names of the classes.\n",
    "\n",
    "    Returns:\n",
    "        predicted_label: string, the predicted class label.\n",
    "    \"\"\"\n",
    "\n",
    "    # read the image from image_path with the help of OpenCV\n",
    "    image_file = cv2.imread(image_path)\n",
    "    # resize the image to (224, 224) as our model accepts the input of size (224, 224)\n",
    "    resized_image = cv2.resize(image_file, (224, 224))\n",
    "\n",
    "    # Preprocess the image data if necessary (e.g., normalization)\n",
    "\n",
    "    # Expand the dimensions to match the model's input shape\n",
    "    input_image = np.expand_dims(resized_image, axis=0)\n",
    "\n",
    "    # Make the prediction using the model\n",
    "    prediction_probabilities = nn_model.predict(input_image, verbose=0)\n",
    "\n",
    "    # Get the index of the predicted class with the highest probability\n",
    "    predicted_class_index = np.argmax(prediction_probabilities, axis=1)[0]\n",
    "\n",
    "    # Get the corresponding class label\n",
    "    predicted_label = classes[predicted_class_index]\n",
    "\n",
    "    print(\"Predicted Label: \", predicted_label)\n",
    "    print(\"Actual Label: \", image_path.split('/')[1])\n",
    "\n",
    "    plt.imshow(image_file)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# list all the directories in our main dataset path\n",
    "for directory in os.listdir(DATASET_PATH):\n",
    "    # pick a single random image from each subdirectory of the main dataset path\n",
    "    for img in np.random.choice(os.listdir(os.path.join(DATASET_PATH, directory)), size = 3):\n",
    "        # perform prediction on each image that is being chosen\n",
    "        predict_image(os.path.join(DATASET_PATH, directory, img), model, labels)\n",
    "        print(\"\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
